apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: train-2-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.13, pipelines.kubeflow.org/pipeline_compilation_time: '2022-09-08T15:13:10.750055',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Train", "inputs": [{"name":
      "model_s3_bucket", "type": "String"}, {"name": "dataset", "type": "Dataset"},
      {"name": "config", "type": "Artifact"}], "name": "Train"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.13}
spec:
  entrypoint: train-2
  templates:
  - name: train
    container:
      args: [--executor_input, '{{$}}', --function_to_execute, train]
      command:
      - sh
      - -c
      - |2

        if ! [ -x "$(command -v pip)" ]; then
            python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
        fi

        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.13' && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - |2+

        import kfp
        from kfp.v2 import dsl
        from kfp.v2.dsl import *
        from typing import *

        def train(
            model_S3_bucket: str,
            dataset: Input[Dataset],
            config: Input[Artifact],
            model: Output[Model]
        ):

            import logging
            import glob
            import yaml
            import os

            logging.info("model.path:"+model.path)
            logging.info(config.metadata)

            MINIO_SERVICE_HOST="minio-service.kubeflow.svc.cluster.local"
            MINIO_SERVICE_PORT="9000"
            #TODO: change these to using Kubeflow's Minio Secrets
            MINIO_SERVICE_ACCESS_KEY="minio"
            MINIO_SERVICE_SECRET_KEY="minio123"
            MINIO_SERVICE_SECURITY_OPTION=False

            from minio import Minio
            minio_client = Minio(
                f"{MINIO_SERVICE_HOST+':'+MINIO_SERVICE_PORT}",
                access_key = MINIO_SERVICE_ACCESS_KEY,
                secret_key = MINIO_SERVICE_SECRET_KEY,
                secure     = MINIO_SERVICE_SECURITY_OPTION
            )

            logging.info(f"connected to Minio Server at minio-service.kubeflow.svc.cluster.local:9000")

            def _yaml_to_env(yaml_file, env_file, data_path):

                yaml_f = open(yaml_file,'r')
                env_f = open(env_file,'w')
                hyperparams = yaml.safe_load(yaml_f)
                hyperparams['data_path'] = data_path
                logging.info("Loading hyperparams:")
                print("Loading hyperparams:")
                for key in hyperparams:
                    logging.info(f"{key} = {hyperparams[key]}")
                    print(f"{key} = {hyperparams[key]}")
                    if isinstance(hyperparams[key], str):
                        env_f.write(f"{key} = '{hyperparams[key]}'\n")
                    else: env_f.write(f"{key} = {hyperparams[key]}\n")

            def _train():
                logging.info("Traning commencing.")
                os.system("python3 -m kws_streaming.train.model_train_eval ds_tc_resnet --alsologtostderr")
                logging.info("Training completed.")

            def _upload_local_directory_to_minio(local_path, bucket_name, minio_path):
                assert os.path.isdir(local_path)
                for local_file in glob.glob(local_path + '/**'):
                    local_file = local_file.replace(os.sep, "/") # Replace \ with / on Windows
                    if not os.path.isfile(local_file):
                        _upload_local_directory_to_minio(
                            local_file, bucket_name, minio_path + "/" + os.path.basename(local_file))
                    else:
                        remote_path = os.path.join(
                            minio_path, local_file[1 + len(local_path):])
                        remote_path = remote_path.replace(
                            os.sep, "/")  # Replace \ with / on Windows
                        minio_client.fput_object(bucket_name, remote_path, local_file)

            model.metadata = {
                "version":"v0.1.1",
                "S3_URI":f"S3://{model_S3_bucket}/saved_model"
                }

            _yaml_to_env(
                yaml_file = config.metadata["local_path"],
                env_file = "hparam.env",
                data_path = dataset.metadata["local_path"])
            _train()
            _upload_local_directory_to_minio(
                local_path = "./train_res/ds_tc_resnet/non_stream",
                bucket_name = model_S3_bucket,
                minio_path = "saved_model/1")

            logging.info("Model uploaded to minio bucket.")

      image: capoolebugchat/kws-training:v0.7.0
    inputs:
      artifacts:
      - {name: config, path: /tmp/inputs/config/data}
      - {name: dataset, path: /tmp/inputs/dataset/data}
      - {name: model_s3_bucket, path: /tmp/inputs/model_S3_bucket/data}
    outputs:
      artifacts:
      - {name: train-model, path: /tmp/outputs/model/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.13
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--executor_input", {"executorInput": null}, "--function_to_execute",
          "train"], "command": ["sh", "-c", "\nif ! [ -x \"$(command -v pip)\" ];
          then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get
          install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet     --no-warn-script-location ''kfp==1.8.13'' && \"$0\"
          \"$@\"\n", "sh", "-ec", "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\"
          > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
          "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing
          import *\n\ndef train(\n    model_S3_bucket: str,\n    dataset: Input[Dataset],\n    config:
          Input[Artifact],\n    model: Output[Model]\n):\n\n    import logging\n    import
          glob\n    import yaml\n    import os\n\n    logging.info(\"model.path:\"+model.path)\n    logging.info(config.metadata)\n\n    MINIO_SERVICE_HOST=\"minio-service.kubeflow.svc.cluster.local\"\n    MINIO_SERVICE_PORT=\"9000\"\n    #TODO:
          change these to using Kubeflow''s Minio Secrets\n    MINIO_SERVICE_ACCESS_KEY=\"minio\"\n    MINIO_SERVICE_SECRET_KEY=\"minio123\"\n    MINIO_SERVICE_SECURITY_OPTION=False\n\n    from
          minio import Minio\n    minio_client = Minio(\n        f\"{MINIO_SERVICE_HOST+'':''+MINIO_SERVICE_PORT}\",\n        access_key
          = MINIO_SERVICE_ACCESS_KEY,\n        secret_key = MINIO_SERVICE_SECRET_KEY,\n        secure     =
          MINIO_SERVICE_SECURITY_OPTION\n    )\n\n    logging.info(f\"connected to
          Minio Server at minio-service.kubeflow.svc.cluster.local:9000\")\n\n    def
          _yaml_to_env(yaml_file, env_file, data_path):\n\n        yaml_f = open(yaml_file,''r'')\n        env_f
          = open(env_file,''w'')\n        hyperparams = yaml.safe_load(yaml_f)\n        hyperparams[''data_path'']
          = data_path\n        logging.info(\"Loading hyperparams:\")\n        print(\"Loading
          hyperparams:\")\n        for key in hyperparams:\n            logging.info(f\"{key}
          = {hyperparams[key]}\")\n            print(f\"{key} = {hyperparams[key]}\")\n            if
          isinstance(hyperparams[key], str):\n                env_f.write(f\"{key}
          = ''{hyperparams[key]}''\\n\")\n            else: env_f.write(f\"{key} =
          {hyperparams[key]}\\n\")\n\n    def _train():\n        logging.info(\"Traning
          commencing.\")\n        os.system(\"python3 -m kws_streaming.train.model_train_eval
          ds_tc_resnet --alsologtostderr\")\n        logging.info(\"Training completed.\")\n\n    def
          _upload_local_directory_to_minio(local_path, bucket_name, minio_path):\n        assert
          os.path.isdir(local_path)\n        for local_file in glob.glob(local_path
          + ''/**''):\n            local_file = local_file.replace(os.sep, \"/\")
          # Replace \\ with / on Windows\n            if not os.path.isfile(local_file):\n                _upload_local_directory_to_minio(\n                    local_file,
          bucket_name, minio_path + \"/\" + os.path.basename(local_file))\n            else:\n                remote_path
          = os.path.join(\n                    minio_path, local_file[1 + len(local_path):])\n                remote_path
          = remote_path.replace(\n                    os.sep, \"/\")  # Replace \\
          with / on Windows\n                minio_client.fput_object(bucket_name,
          remote_path, local_file)\n\n    model.metadata = {\n        \"version\":\"v0.1.1\",\n        \"S3_URI\":f\"S3://{model_S3_bucket}/saved_model\"\n        }\n\n    _yaml_to_env(\n        yaml_file
          = config.metadata[\"local_path\"],\n        env_file = \"hparam.env\",\n        data_path
          = dataset.metadata[\"local_path\"])\n    _train()\n    _upload_local_directory_to_minio(\n        local_path
          = \"./train_res/ds_tc_resnet/non_stream\",\n        bucket_name = model_S3_bucket,\n        minio_path
          = \"saved_model/1\")\n\n    logging.info(\"Model uploaded to minio bucket.\")\n\n"],
          "image": "capoolebugchat/kws-training:v0.7.0"}}, "inputs": [{"name": "model_S3_bucket",
          "type": "String"}, {"name": "dataset", "type": "Dataset"}, {"name": "config",
          "type": "Artifact"}], "name": "Train", "outputs": [{"name": "model", "type":
          "Model"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: train-2
    inputs:
      artifacts:
      - {name: config}
      - {name: dataset}
      - {name: model_s3_bucket}
    dag:
      tasks:
      - name: train
        template: train
        arguments:
          artifacts:
          - {name: config, from: '{{inputs.artifacts.config}}'}
          - {name: dataset, from: '{{inputs.artifacts.dataset}}'}
          - {name: model_s3_bucket, from: '{{inputs.artifacts.model_s3_bucket}}'}
  arguments:
    parameters:
    - {name: model_s3_bucket}
    - {name: dataset}
    - {name: config}
    artifacts:
    - name: model_s3_bucket
      raw: {data: '{{workflow.parameters.model_s3_bucket}}'}
    - name: dataset
      raw: {data: '{{workflow.parameters.dataset}}'}
    - name: config
      raw: {data: '{{workflow.parameters.config}}'}
  serviceAccountName: pipeline-runner
