{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import load_component_from_file\n",
    "train = load_component_from_file(\"components/train/component_SDKv2.yaml\")\n",
    "train.component_spec.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lebugcat/miniconda3/envs/kws-dev-env/lib/python3.9/site-packages/kfp/compiler/compiler.py:79: UserWarning: V2_COMPATIBLE execution mode is at Beta quality. Some pipeline features may not work as expected.\n",
      "  warnings.warn('V2_COMPATIBLE execution mode is at Beta quality.'\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.v2.dsl import component, Input, Output, Artifact\n",
    "from typing import Optional, Dict\n",
    "\n",
    "@component(\n",
    "    base_image=\"docker.io/capoolebugchat/kws-training:v0.8.0\"\n",
    ")\n",
    "def directory_discovery_comp():\n",
    "    import os\n",
    "    os.system(\"/bin/bash -c -- while true; do sleep 1000; done;\")\n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "    name = \"Test pipe\",\n",
    "    description= \"None\"\n",
    ")\n",
    "def pipeline2():\n",
    "    task = directory_discovery_comp()\n",
    "\n",
    "kfp.compiler.Compiler(mode = kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE).compile(\n",
    "    pipeline2, \"p.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lebugcat/miniconda3/envs/kws-dev-env/lib/python3.9/site-packages/kfp/compiler/compiler.py:79: UserWarning: V2_COMPATIBLE execution mode is at Beta quality. Some pipeline features may not work as expected.\n",
      "  warnings.warn('V2_COMPATIBLE execution mode is at Beta quality.'\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.v2.dsl import component, Input, Output, Artifact\n",
    "from typing import Optional, Dict\n",
    "from kfp.onprem import mount_pvc\n",
    "\n",
    "@component(\n",
    "    output_component_file=\"testcompv2.yaml\"\n",
    ")\n",
    "def generate_my_Artifacts(\n",
    "    outp: Output[Artifact]\n",
    "):\n",
    "    import logging\n",
    "    import os\n",
    "    os.system(\"ls //\")\n",
    "    os.system(\"ls /mnt/pipeline\")\n",
    "    os.system(\"ls /mnt/pipeline/test-train-dataset\")\n",
    "    logging.info(\"Path:\"+outp.path)\n",
    "    logging.info(\"URI:\"+outp.path)\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"test pipeline\"\n",
    ")\n",
    "def pipeline():\n",
    "    generate_my_Artifacts_task = generate_my_Artifacts()\n",
    "    generate_my_Artifacts_task.apply(mount_pvc(\"example-dataset\"))\n",
    "\n",
    "from kfp.compiler import Compiler\n",
    "Compiler(mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE).compile(\n",
    "    pipeline,\n",
    "    \"test_pipe.yaml\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.components import C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-rclone\n",
      "  Downloading python_rclone-0.0.2-py3-none-any.whl (4.2 kB)\n",
      "Installing collected packages: python-rclone\n",
      "Successfully installed python-rclone-0.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wanted_words', \"'non_trigger,trigger'\"],\n",
       " ['data_path', \"'td2'\"],\n",
       " ['train_res', \"'train_res3/ds_tc_resnet/'\"],\n",
       " ['split_data', '0'],\n",
       " ['clip_duration_ms', '1000'],\n",
       " ['background_volume', '0.1'],\n",
       " ['background_frequency', '0.8'],\n",
       " ['training_steps', \"'2,2,2,2,2,2'\"],\n",
       " ['learning_rate', \"'0.01,0.005,0.002,0.001,0.0005,0.0002'\"],\n",
       " ['lr_schedule', \"'linear'\"],\n",
       " ['batch_size', '1'],\n",
       " ['eval_step_interval', '1'],\n",
       " ['mel_upper_edge_hertz', '7600.0'],\n",
       " ['mel_lower_edge_hertz', '20.0'],\n",
       " ['window_size_ms', '30.0'],\n",
       " ['window_stride_ms', '10.0'],\n",
       " ['mel_num_bins', '80'],\n",
       " ['dct_num_features', '40'],\n",
       " ['use_spec_augment', '1'],\n",
       " ['time_masks_number', '2'],\n",
       " ['time_mask_max_size', '25'],\n",
       " ['frequency_masks_number', '2'],\n",
       " ['frequency_mask_max_size', '7'],\n",
       " ['pick_deterministically', '1']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "configuration = yaml.safe_load(open(\"components/2_train/h_param.yaml\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.v2.dsl import component, Output, Input, Artifact\n",
    "from ml_metadata.proto.metadata_store_pb2 import ArtifactType\n",
    "\n",
    "@component(\n",
    "    output_component_file=\"c.yaml\"\n",
    ")\n",
    "def _register_at(\n",
    ") -> ArtifactType:\n",
    "    \n",
    "    from ml_metadata.proto.metadata_store_pb2 import ArtifactType\n",
    "    from ml_metadata.proto import metadata_store_pb2\n",
    "    data_type = ArtifactType\n",
    "    data_type.name = \"DataSet\"\n",
    "    data_type.properties[\"description\"] = metadata_store_pb2.STRING\n",
    "    data_type.properties[\"day\"] = metadata_store_pb2.INT\n",
    "    data_type.properties[\"split\"] = metadata_store_pb2.STRING\n",
    "    return data_type\n",
    "\n",
    "@component(\n",
    "    output_component_file=\"c2.yaml\"\n",
    ")\n",
    "def _save_a(\n",
    "    custom_artifacts_name: str\n",
    ") -> ArtifactType:\n",
    "    \n",
    "    from ml_metadata.proto.metadata_store_pb2 import ArtifactType\n",
    "    from ml_metadata.proto import metadata_store_pb2\n",
    "    data_type = ArtifactType\n",
    "    data_type.name = \"DataSet\"\n",
    "    data_type.properties[\"description\"] = metadata_store_pb2.STRING\n",
    "    data_type.properties[\"day\"] = metadata_store_pb2.INT\n",
    "    data_type.properties[\"split\"] = metadata_store_pb2.STRING\n",
    "    return data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 30, 'b': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_metadata as mlmd\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.fake_database.SetInParent() # Sets an empty fake database proto.\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ArtifactTypes, e.g., Data and Model\n",
    "data_type = metadata_store_pb2.ArtifactType()\n",
    "data_type.name = \"DataSet\"\n",
    "data_type.properties[\"day\"] = metadata_store_pb2.INT\n",
    "data_type.properties[\"split\"] = metadata_store_pb2.STRING\n",
    "data_type_id = store.put_artifact_type(data_type)\n",
    "\n",
    "model_type = metadata_store_pb2.ArtifactType()\n",
    "model_type.name = \"SavedModel\"\n",
    "model_type.properties[\"version\"] = metadata_store_pb2.INT\n",
    "model_type.properties[\"name\"] = metadata_store_pb2.STRING\n",
    "model_type_id = store.put_artifact_type(model_type)\n",
    "\n",
    "# Query all registered Artifact types.\n",
    "artifact_types = store.get_artifact_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lebugcat/Desktop/FTech/Projects/KWS-ContinuousTraining'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type2 = metadata_store_pb2.ArtifactType()\n",
    "data_type2.name = \"DataSet\"\n",
    "data_type2.properties[\"day\"] = metadata_store_pb2.INT\n",
    "data_type2.properties[\"split\"] = metadata_store_pb2.STRING\n",
    "data_type_id2 = store.put_artifact_type(data_type2)\n",
    "data_type_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kws-dev-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a192e72af163c78e5ecb2f39af3cac0b99b94b35df0ed122b563314cb768475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
