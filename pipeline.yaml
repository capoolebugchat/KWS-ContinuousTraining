apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: kws-train-test-pipe-
  annotations:
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.3
    pipelines.kubeflow.org/pipeline_compilation_time: '2022-08-25T14:40:38.727714'
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "h_param.yaml",
      "name": "config_file_url", "optional": true, "type": "String"}, {"default":
      "test_dataset", "name": "dataset_path", "optional": true, "type": "String"},
      {"default": "model-store", "name": "model_s3_bucket", "optional": true, "type":
      "String"}, {"default": "", "name": "pipeline-root"}, {"default": "pipeline/KWS-train-test-pipe",
      "name": "pipeline-name"}], "name": "KWS-train-test-pipe"}'
    pipelines.kubeflow.org/v2_pipeline: "true"
  labels:
    pipelines.kubeflow.org/v2_pipeline: "true"
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.3
spec:
  entrypoint: kws-train-test-pipe
  templates:
  - name: deploy
    container:
      args:
      - sh
      - -c
      - (python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet                 --no-warn-script-location 'kserve==0.8.0'
        'kubernetes==18.20.0' 'kfp==1.8.3' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet                 --no-warn-script-location 'kserve==0.8.0'
        'kubernetes==18.20.0' 'kfp==1.8.3' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef deploy(\n    model:\
        \ Input[Model],\n):\n\n    import logging\n    from kubernetes import client\n\
        \    import kserve\n    from kserve import KServeClient\n    from kserve import\
        \ constants\n    from kserve import V1beta1PredictorSpec\n    from kserve\
        \ import V1beta1TFServingSpec\n    from kserve import V1beta1InferenceServiceSpec\n\
        \    from kserve import V1beta1InferenceService\n\n    default_model_spec\
        \ = V1beta1InferenceServiceSpec(\n        predictor=V1beta1PredictorSpec(\n\
        \            tensorflow=V1beta1TFServingSpec(\n                storage_uri=model.metadata[\"\
        S3_URI\"]\n                )\n            )\n        )\n\n    isvc = V1beta1InferenceService(\n\
        \        api_version=constants.KSERVE_V1BETA1,\n        kind=constants.KSERVE_KIND,\n\
        \        metadata=client.V1ObjectMeta(\n            name='auto-deployed-model',\
        \ \n            namespace='kubeflow-user-example-com'\n            ),\n  \
        \          spec=default_model_spec\n        )\n\n    client = KServeClient()\n\
        \    client.set_credentials(\n        storage_type = \"S3\",\n        namespace\
        \ = \"kubeflow-user-example-com\",\n        service_account = \"default-editor\"\
        \n    )\n    '''mlpipeline-minio-artifact -n kubeflow-user-example-com'''\n\
        \    logging.info(\"Client created\")\n\n    client.create(isvc)\n    logging.info(\"\
        ISVC created. Object sent to K8s apiserver\")\n\n    client.wait_isvc_ready(\n\
        \        name = 'auto-deployed-model',\n        namespace = 'kubeflow-user-example-com',\n\
        \        timeout_seconds = 300\n        )\n    logging.info(\"ISVC ready.\
        \ Model deployed\")\n\n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - deploy
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, deploy, --pipeline_name,
        '{{inputs.parameters.pipeline-name}}', --run_id, $(KFP_RUN_ID), --run_resource,
        workflows.argoproj.io/$(WORKFLOW_ID), --namespace, $(KFP_NAMESPACE), --pod_name,
        $(KFP_POD_NAME), --pod_uid, $(KFP_POD_UID), --pipeline_root, '{{inputs.parameters.pipeline-root}}',
        --enable_caching, $(ENABLE_CACHING), --, --]
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {}, "inputArtifacts":
          {"model": {"metadataPath": "/tmp/inputs/model/data", "schemaTitle": "system.Model",
          "instanceSchema": "", "schemaVersion": "0.0.1"}}, "outputParameters": {},
          "outputArtifacts": {}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: pipeline-name}
      - {name: pipeline-root}
      artifacts:
      - {name: train-model, path: /tmp/inputs/model/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{"digest": "732f5a44df8cd121c250b88e3270694f6f94a7570dd2987f4b3c4e79e9fb7468",
          "url": "components/deploy/component_SDKv2.yaml"}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.3
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/enable_caching: "true"
    initContainers:
    - command: [launcher, --copy, /kfp-launcher/launch]
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.3
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  - name: init-artifacts
    container:
      args:
      - sh
      - -c
      - (python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet                 --no-warn-script-location 'kfp==1.8.3'
        || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location
        'kfp==1.8.3' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - |2+

        from kfp.v2.dsl import *
        from typing import *

        def init_artifacts(
            config_path: str,
            dataset_path: str,
            version: Optional[str],
            train_config: Output[Artifact],
            train_dataset: Output[Dataset],
        ) -> None:

            train_config.metadata = {"version":version, "local_path":config_path}
            train_dataset.metadata= {"version":version, "local_path":dataset_path}

            import os
            os.system("printenv")

      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - init_artifacts
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, init-artifacts, --pipeline_name,
        '{{inputs.parameters.pipeline-name}}', --run_id, $(KFP_RUN_ID), --run_resource,
        workflows.argoproj.io/$(WORKFLOW_ID), --namespace, $(KFP_NAMESPACE), --pod_name,
        $(KFP_POD_NAME), --pod_uid, $(KFP_POD_UID), --pipeline_root, '{{inputs.parameters.pipeline-root}}',
        --enable_caching, $(ENABLE_CACHING), --, 'config_path={{inputs.parameters.config_file_url}}',
        'dataset_path={{inputs.parameters.dataset_path}}', version=v0.0.1, --]
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {"config_path": {"type":
          "STRING"}, "dataset_path": {"type": "STRING"}, "version": {"type": "STRING"}},
          "inputArtifacts": {}, "outputParameters": {}, "outputArtifacts": {"train_config":
          {"schemaTitle": "system.Artifact", "instanceSchema": "", "schemaVersion":
          "0.0.1", "metadataPath": "/tmp/outputs/train_config/data"}, "train_dataset":
          {"schemaTitle": "system.Dataset", "instanceSchema": "", "schemaVersion":
          "0.0.1", "metadataPath": "/tmp/outputs/train_dataset/data"}}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: config_file_url}
      - {name: dataset_path}
      - {name: pipeline-name}
      - {name: pipeline-root}
    outputs:
      artifacts:
      - {name: init-artifacts-train_config, path: /tmp/outputs/train_config/data}
      - {name: init-artifacts-train_dataset, path: /tmp/outputs/train_dataset/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{"digest": "9ec74bf31f5fc7a27b1af807a2566c65ab197fab79a744065e67f9004eecef89",
          "url": "components/init_artifacts/component_SDKv2.yaml"}'
        pipelines.kubeflow.org/arguments.parameters: '{"config_path": "{{inputs.parameters.config_file_url}}",
          "dataset_path": "{{inputs.parameters.dataset_path}}", "version": "v0.0.1"}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.3
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/enable_caching: "true"
    initContainers:
    - command: [launcher, --copy, /kfp-launcher/launch]
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.3
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  - name: kws-train-test-pipe
    inputs:
      parameters:
      - {name: config_file_url}
      - {name: dataset_path}
      - {name: model_s3_bucket}
      - {name: pipeline-name}
      - {name: pipeline-root}
    dag:
      tasks:
      - name: deploy
        template: deploy
        dependencies: [train]
        arguments:
          parameters:
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-root, value: '{{inputs.parameters.pipeline-root}}'}
          artifacts:
          - {name: train-model, from: '{{tasks.train.outputs.artifacts.train-model}}'}
      - name: init-artifacts
        template: init-artifacts
        arguments:
          parameters:
          - {name: config_file_url, value: '{{inputs.parameters.config_file_url}}'}
          - {name: dataset_path, value: '{{inputs.parameters.dataset_path}}'}
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-root, value: '{{inputs.parameters.pipeline-root}}'}
      - name: train
        template: train
        dependencies: [init-artifacts]
        arguments:
          parameters:
          - {name: model_s3_bucket, value: '{{inputs.parameters.model_s3_bucket}}'}
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-root, value: '{{inputs.parameters.pipeline-root}}'}
          artifacts:
          - {name: init-artifacts-train_config, from: '{{tasks.init-artifacts.outputs.artifacts.init-artifacts-train_config}}'}
          - {name: init-artifacts-train_dataset, from: '{{tasks.init-artifacts.outputs.artifacts.init-artifacts-train_dataset}}'}
  - name: train
    container:
      args:
      - sh
      - -c
      - (python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet                 --no-warn-script-location 'minio'
        'ensurepip' 'kfp==1.8.3' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
        install --quiet                 --no-warn-script-location 'minio' 'ensurepip'
        'kfp==1.8.3' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp -d)
        printf "%s" "$0" > "$program_path/ephemeral_component.py"
        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
      - |2+

        from kfp.v2.dsl import *
        from typing import *

        def train(
            model_S3_bucket: str,
            dataset: Input[Dataset],
            config: Input[Artifact],
            model: Output[Model]
        ):

            import logging
            import glob
            import yaml
            import os

            logging.info(dataset.path)
            logging.info(dataset.metadata)
            logging.info(config.path)
            logging.info(config.metadata)

            from minio import Minio
            minio_client = Minio(
                "minio-service.kubeflow.svc.cluster.local:9000",
                access_key="minio",
                secret_key="minio123",
                secure=False
            )

            logging.info(f"connected to Minio Server at minio-service.kubeflow.svc.cluster.local:9000")

            def _yaml_to_env(yaml_file, env_file, data_path):

                yaml_f = open(yaml_file,'r')
                env_f = open(env_file,'w')
                hyperparams = yaml.safe_load(yaml_f)
                hyperparams['data_path'] = data_path
                logging.info("Loading hyperparams:")
                print("Loading hyperparams:")
                for key in hyperparams:
                    logging.info(f"{key} = {hyperparams[key]}")
                    print(f"{key} = {hyperparams[key]}")
                    if isinstance(hyperparams[key], str):
                        env_f.write(f"{key} = '{hyperparams[key]}'\n")
                    else: env_f.write(f"{key} = {hyperparams[key]}\n")

            def _train():
                logging.info("Traning commencing.")
                os.system("python -m kws_streaming.train.model_train_eval ds_tc_resnet --alsologtostderr")
                logging.info("Training completed.")

            def _upload_local_directory_to_minio(local_path, bucket_name, minio_path):
                assert os.path.isdir(local_path)
                for local_file in glob.glob(local_path + '/**'):
                    local_file = local_file.replace(os.sep, "/") # Replace \ with / on Windows
                    if not os.path.isfile(local_file):
                        _upload_local_directory_to_minio(
                            local_file, bucket_name, minio_path + "/" + os.path.basename(local_file))
                    else:
                        remote_path = os.path.join(
                            minio_path, local_file[1 + len(local_path):])
                        remote_path = remote_path.replace(
                            os.sep, "/")  # Replace \ with / on Windows
                        minio_client.fput_object(bucket_name, remote_path, local_file)

            print(config.path)
            print(dataset.path)

            model.metadata = {
                "version":"v0.1.1",
                "S3_URI":"S3://model-store/saved_model"
                }

            _yaml_to_env(
                yaml_file = config.metadata["local_path"],
                env_file = "hparam.env",
                data_path = dataset.metadata["local_path"])
            _train()
            _upload_local_directory_to_minio(
                local_path = "./train_res/ds_tc_resnet/non_stream",
                bucket_name = model_S3_bucket,
                minio_path = "saved_model/1")

            logging.info("Model uploaded to minio bucket.")

      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - train
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, train, --pipeline_name, '{{inputs.parameters.pipeline-name}}',
        --run_id, $(KFP_RUN_ID), --run_resource, workflows.argoproj.io/$(WORKFLOW_ID),
        --namespace, $(KFP_NAMESPACE), --pod_name, $(KFP_POD_NAME), --pod_uid, $(KFP_POD_UID),
        --pipeline_root, '{{inputs.parameters.pipeline-root}}', --enable_caching,
        $(ENABLE_CACHING), --, 'model_S3_bucket={{inputs.parameters.model_s3_bucket}}',
        --]
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      - {name: KFP_V2_IMAGE, value: 'capoolebugchat/kws-training:v0.4.0'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {"model_S3_bucket":
          {"type": "STRING"}}, "inputArtifacts": {"config": {"metadataPath": "/tmp/inputs/config/data",
          "schemaTitle": "system.Artifact", "instanceSchema": "", "schemaVersion":
          "0.0.1"}, "dataset": {"metadataPath": "/tmp/inputs/dataset/data", "schemaTitle":
          "system.Dataset", "instanceSchema": "", "schemaVersion": "0.0.1"}}, "outputParameters":
          {}, "outputArtifacts": {"model": {"schemaTitle": "system.Model", "instanceSchema":
          "", "schemaVersion": "0.0.1", "metadataPath": "/tmp/outputs/model/data"}}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: capoolebugchat/kws-training:v0.4.0
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: model_s3_bucket}
      - {name: pipeline-name}
      - {name: pipeline-root}
      artifacts:
      - {name: init-artifacts-train_config, path: /tmp/inputs/config/data}
      - {name: init-artifacts-train_dataset, path: /tmp/inputs/dataset/data}
    outputs:
      artifacts:
      - {name: train-model, path: /tmp/outputs/model/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{"digest": "cf531ad129b4e58442380ce1bde3799483d6c7452a68ac1e714473728996a23d",
          "url": "components/train/component_SDKv2.yaml"}'
        pipelines.kubeflow.org/arguments.parameters: '{"model_S3_bucket": "{{inputs.parameters.model_s3_bucket}}"}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.3
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/enable_caching: "true"
    initContainers:
    - command: [launcher, --copy, /kfp-launcher/launch]
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.3
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  arguments:
    parameters:
    - {name: config_file_url, value: h_param.yaml}
    - {name: dataset_path, value: test_dataset}
    - {name: model_s3_bucket, value: model-store}
    - {name: pipeline-root, value: ''}
    - {name: pipeline-name, value: pipeline/KWS-train-test-pipe}
  serviceAccountName: pipeline-runner
